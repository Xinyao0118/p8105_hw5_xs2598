---
title: "hw5_xw2598"
author: "Xinyao Wu"
date: "2018/11/4"
output: github_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(purrr)
```

##Problem 1

*tidy data
```{r tidy_data}
#a dataframe containing all file names
file_ls =tibble(
  path = list.files("data/")
  )
#function:read data
read_data = function(x){
  path = str_c("data/",x)
  file = read.csv(path)
  file
}
#combine data
file = file_ls %>% 
mutate(map(file_ls$path,read_data)) %>% 
  unnest() %>% 
  #separate path name 
  separate(path,into = c("group","subject_Id"), sep = "_") %>% 
  #tidy path name
  mutate(
    subject_Id = str_replace(subject_Id,".csv", " "),
    group = as.factor(group)
      ) %>% 
  #tidy data
 gather(key = "week", value = value, week_1:week_8) %>% 
  mutate(
    week = as.factor(str_replace(week,"week_", " "))
  ) 

file 
```
This dataset contains 4 variables: group, subject id, week and value. (1)group:control group or experimental group.(2)subject id: indicate different subjects.(3)week: indicate time, ranging from 1 to 8 (4)value: the observation outcome.


*make a plot
```{r make_plots}
file %>% 
ggplot(aes(x = week, y = value, group= subject_Id,color = subject_Id))+
  geom_line()+
  facet_grid(~group)+
 
  labs(
    y = "Observation value",
    color = "Subject Id",
    title = "Observation value change tendency from control and experimental subjects "
  )

```

####Comments:
The observation value change from control group are more static than the experimental group, the latter has an obvious increasing tendency over time. In the control group, the range of obervation value is stable in [-2,4].However, in the experimental group, the range of obervation value changed over time which was [-1.25,3.75] in the 1st week and then changed to [2.5,7.5] in the 8th week.  

##Problem2
*read and clean data
```{r collapse=TRUE,warning=FALSE}
wp_df = read.csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv") %>% 
janitor::clean_names() %>% 
  mutate(city_state = str_c(city,state,sep = ","))

#date range 
pull(wp_df,reported_date) %>%
  as.character() %>% 
  range()
#victim age range
pull(wp_df,victim_age) %>%as.character() %>% as.integer() %>% range(na.rm =TRUE)
```
####Describe the raw data:
This data contains `r nrow(wp_df)` homicides records included information such as reported date ranged from 20070101 to 20171231 and victim age ranged from 0 to 102 years old, and victim`s name,race,sex and the location details and disposition state of these homicides.

A weird thing is that the number of city_state  is not equal to the number of cities. So I check the dataset and find the city "Tulsa" shows up in two states:
```{r collapse=TRUE}
#the number of city_state 
nrow(distinct(wp_df,city_state))
# the number of cities
nrow(distinct(wp_df,city))
#check the dataset and find the city "Tulsa" shows up in two states:
 filter(wp_df,city == "Tulsa") %>% 
   distinct(state)
```
Since Tulsa in the state of Oklahoma, the record of "Tulsa, AL" might be a typo. However, we are not sure whether the city name or the state name in this record is wrong. Since there is only one "Tulsa, AL", we choose to exclude this record.

* homicide table
```{r}
#calculated the total number of homicides and unsolved homicides
homicide = wp_df %>% 
  #exclude "Tulsa, AL"
  filter(city_state != "Tulsa,AL") %>%
  group_by(city_state) %>% 
  mutate(
    unsolved = ifelse(disposition == "Closed by arrest",0,1)
      ) %>% 
  summarise(
    total_homicides = n(),
    unsolved_homicides = sum(unsolved)
  ) %>% 
  arrange(desc(total_homicides))
homicide %>% 
  knitr::kable()
```

*Baltimore analysis
```{r  collapse = TRUE}
 balti = homicide  %>% 
#select the city of Baltimore,MD
  filter(city_state == "Baltimore,MD") 
#using prop.test function 
balti = prop.test(balti$unsolved_homicides, balti$total_homicides) 
#turn the outcome into a tidy tribble
balti = broom::tidy(balti)  
#pull the estimated proportion and
pull(balti,estimate)
#confidence intervals
#low limit
pull(balti,conf.low)
#high limit
pull(balti,conf.high)
```

####Comments:
The estimated proportion of homicides in Baltimore is 64.56% and its 95% confidence interval is [ 62.75%, 66.31%]

```{r warning=FALSE}
prop_df = homicide %>% 
  mutate(
    test = map2(.x = unsolved_homicides, .y = total_homicides, prop.test),
    test = map(test,broom::tidy)
         )  %>% 
  unnest() %>% 
  select(city_state, estimate, conf.low, conf.high) 
prop_df %>% arrange(desc(estimate))
```

###comments
The top 5 cities with the most unsolved homicides proportion are:Chicago, New Orleans,Baltimore, San Bernardino, Buffalo. The homicides proportion estimates range `r pull(prop_df,estimate) %>% range()`

```{r plot}
prop_df %>% 
  ggplot(aes(x = reorder(city_state,estimate), y =estimate))+
  geom_point()+
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high))+
  theme(
    axis.text.x = element_text(angle = 90,hjust = 1,size = 6.5)
  )+
  labs(
    title = "The proportions of unsolved homicides in 50 US cities",
    y = "Proportion of unsolved homicides",
    x = "City",
    caption = "Data from Washington post"
  )
```

####Comments
Cities who has a wider confidence interbals would have a bigger sample size compared to those who has a narrower CI. Seen from this plot, Chicago has the obvious highest proportion of unsolved homicides which is above 70%. Also, New Orieans and Baltimore has a high proportion of unsolved homicides with narrow CI, which means not only do they have high unsolved homicides proportion but also have a large total homicides number. To combine those above, the three cities seem dangerous according to the homocides analysis.



























